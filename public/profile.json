{"data":{"user":{"name":"Jordan Deklerk","bio":"Transforming AI, one attention head at a time.","avatarUrl":"https://avatars.githubusercontent.com/u/111652310?u=1eb0b5315802b7d8dad0edb4e1bcb78c4399d83b&v=4","location":"Saint Cloud, FL","pinnedItems":{"totalCount":4,"edges":[{"node":{"name":"EHR-BERT","description":"BERT style transformer model on CMS synthetic EHR data for diagnosis and procedure prediction in PyTorch.","forkCount":0,"stargazers":{"totalCount":0},"url":"https://github.com/jordandeklerk/EHR-BERT","id":"R_kgDOL-zO0w","diskUsage":53202,"primaryLanguage":{"name":"Python","color":"#3572A5"}}},{"node":{"name":"Amortized-Bayes","description":"Implementing Bayesian neural networks to minimize the amortization gap in VAEs, investigating their potential to approximate the optimal solution to the amortization interpolation problem in PyTorch.","forkCount":0,"stargazers":{"totalCount":0},"url":"https://github.com/jordandeklerk/Amortized-Bayes","id":"R_kgDOLe9MFw","diskUsage":7904,"primaryLanguage":{"name":"Jupyter Notebook","color":"#DA5B0B"}}},{"node":{"name":"SwinViT","description":"Implementing a modified Swin Transformer model in PyTorch on CIFAR-10","forkCount":0,"stargazers":{"totalCount":3},"url":"https://github.com/jordandeklerk/SwinViT","id":"R_kgDOLEUEEw","diskUsage":1846,"primaryLanguage":{"name":"Python","color":"#3572A5"}}},{"node":{"name":"OpenCodeInterpreter-Finetune-SQL","description":"Finetuning coding LLM OpenCodeInterpreter-DS-6.7B for Text-to-SQL Code Generation on a Single A100 GPU in PyTorch.","forkCount":0,"stargazers":{"totalCount":1},"url":"https://github.com/jordandeklerk/OpenCodeInterpreter-Finetune-SQL","id":"R_kgDOLoU4PA","diskUsage":1060,"primaryLanguage":{"name":"Jupyter Notebook","color":"#DA5B0B"}}}]}}}}